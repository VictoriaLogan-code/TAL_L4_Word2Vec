{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y1hsBExwZq2a"
      },
      "source": [
        "# 1. Tester et évaluer un modèle entraîné sur Google News\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS_r82oSZYxm",
        "outputId": "5c573c3b-998e-4751-96fc-fc7f50d87c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: gensim in c:\\python310\\lib\\site-packages (4.3.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\python310\\lib\\site-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\python310\\lib\\site-packages (from gensim) (1.24.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\python310\\lib\\site-packages (from gensim) (1.10.1)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqV5KnWBZaeX",
        "outputId": "dc1888b2-6947-4352-fd38-ed7f2ceeff4d"
      },
      "outputs": [],
      "source": [
        "# Pour obtenir le modèle depuis gensim\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pour utiliser la copie locale du modèle\n",
        "path_to_file = '~/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
        "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The amount of memory occupied by the notebook process once the word vectors are loaded is: 19.6 MB\n"
          ]
        }
      ],
      "source": [
        "#%pip install psutil\n",
        "import psutil\n",
        "import os\n",
        "memory_usage_bytes = psutil.Process(os.getpid()).memory_info().rss\n",
        "memory_usage_mb = round(memory_usage_bytes / (1024 * 1024), 2)\n",
        "print(\"The amount of memory occupied by the notebook process once the word vectors are loaded is:\", memory_usage_mb, \"MB\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Jbb7C48cv89",
        "outputId": "4e3aeb5b-6f60-4ef4-ab7b-16cb76ee62f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension : 300\n"
          ]
        }
      ],
      "source": [
        "# Dimension de l'espace vectoriel dans lequel les mots sont représentés\n",
        "print('Dimension :', w2v_vectors.vector_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vrKpyl5dAIc",
        "outputId": "449ec938-5a27-4baf-f5f3-0623095cd137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille du voc   : 3000000\n",
            "5 mots du voc   : ['company', 'any', 'team', 'against', 'off']\n"
          ]
        }
      ],
      "source": [
        "# Taille du voc (nombre de mots différents) et 5 mots du voc\n",
        "print('Taille du voc   :', len(w2v_vectors))\n",
        "print('5 mots du voc   :', list(w2v_vectors.key_to_index.keys())[100:105])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is the word Vexillology  in the vocabulary? False\n",
            "is the word Quire in the vocabulary? True\n",
            "is the word Clinomania in the vocabulary? False\n",
            "is the word to in the vocabulary? False\n",
            "is the word of in the vocabulary? False\n"
          ]
        }
      ],
      "source": [
        "# Quelques mots hors vocabulaire. Test effectué en incluant les mots les plus rares en anglais\n",
        "test_voc = [\"Vexillology \",\"Quire\",\"Clinomania\",\"to\",\"of\"] \n",
        "for voc in test_voc:\n",
        "    print(f\"is the word {voc} in the vocabulary? {w2v_vectors.has_index_for(voc)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "77v7JXtrgi_w"
      },
      "source": [
        "## 1.e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-abbD9deSmE",
        "outputId": "b0a7da57-6aac-433b-c885-26dbd168c54d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.36"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distance entre les mots `rabbit` et `carrot`\n",
        "round(w2v_vectors.similarity(\"rabbit\", \"carrot\"), 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TJcZ9MP5ifG5"
      },
      "source": [
        "---\n",
        "\n",
        "**Comment mesure-t-on ls distances entre deux mots dans cet espace ?**\n",
        "\n",
        "\n",
        "Dans cet espace, on mesure les distances entre deux mot en utilisant la similarité cosinus, c'est-à-dire qu'on va observer l'angle formé entre les vecteurs représentant les mots. La similarité cosinus calcule le cosinus de cet angle ; ainsi, voici comment interpréter les résultats de cette métrique :     \n",
        "*  1 : les deux vecteurs sont identiques ;\n",
        "*  0 : les deux mots n'ont pas de rapport ;\n",
        "* -1 : les deux mots sont opposés.\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w4tbTAskhju4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wine et grapes : 0.65\n",
            "grapes et happy : 0.07\n",
            "happy et sad : 0.54\n",
            "sad et wine : 0.02\n",
            "claws et grapes : 0.06\n"
          ]
        }
      ],
      "source": [
        "# Distance entre entre 5 paires de mots\n",
        "words = ['wine', 'grapes', 'happy', 'sad', 'claws']\n",
        "\n",
        "for i in range(5):\n",
        "  w1 = words[i]\n",
        "  w2 = words[(i+1)%4]\n",
        "  print(w1, 'et', w2, ':', round(w2v_vectors.similarity(w1, w2), 2))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qyFIPt_3lG0-"
      },
      "source": [
        "---\n",
        "\n",
        "**Les distances obtenues correspondent-t-elles à vos intuitions sur la proximité des sens des mots ?**\n",
        "\n",
        "Ces distances ne correspondent pas toutes à nos intuitions. Effectivement, bien que wine et grapes aient un score de similarity élevé comme on s'y attendait, on observe également une similarité positive plutôt élevée entre ``sad`` et ``happy``, alors qu'on aurait tendance à s'attendre à une valeur négative proche de -1 - de par leur sens opposé. \n",
        "\n",
        "\n",
        " En réfléchissant un peu cependant, ça peut faire sens qu'ils soient proches étant donné que les deux expriment des émotions ; en ce sens là, ils sont proches. Aussi, word2vec est entraîné de sorte à valoriser la similarité des mots se retrouvant souvent ensemble dans les textes. Ce dernier argument nous indique encore une fois pourquoi notre intuition n'était pas correcte, ici.\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.g"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iBfFOBxRmbxS"
      },
      "source": [
        "**Pouvez-vous trouver des mots de sens opposés mais qui sont proches dans l’espace vectoriel ? Comment expliquez vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?**\n",
        "\n",
        "Comme vu ci-dessus, les mots ``happy`` et ``sad`` sont considérés comme plutôt proches par le modèle word2vec pré-entraîné sur le corpus Google News, avec un score de 0.54. D'après le sens opposé des deux mots, on aurait tendance à supposer que leur score soit dans les négatifs, proche de -1. \n",
        "\n",
        "D'après nous, ceci s'explique premièrement par le fait que le modèle word2vec considère deux mots comme proches s'ils ont tendance à se retrouver dans les mêmes documents. Étant donné que le modèle qu'on utilise ici a été pré-entraîné sur le corpus Google News - qui comporte des articles en tous genres - le fait de trouver deux mots évoquant des émotions à sens opposé dans un même document n'est pas très surprenant ; ce qui aurait été le cas s'il s'agissait de textes de personnes évoquant leur vécu par rapport à une situation, par exemple. En somme, ces mots sont considérés comme proches certainement car ils expriment les deux des émotions, et sont donc similaires en cet aspect.\n",
        "\n",
        "L'aspect de qualité ou de défaut est difficile à juger ici, étant donné que cette catégorisation dépendra de l'utilisation que l'on souhaite faire du modèle. Si l'on cherche à classifier des mots comme étant proches lorsqu'ils ont une dfinition, un sens profond, similaire et inversément, alors ce modèle n'est pas adapté."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBNGfz1_q99X",
        "outputId": "3179b1f3-da6c-4301-9fc3-e40721d037d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pearson  Result :\n",
            " statistic = 0.62 \n",
            " pvalue = 1.79632377241771e-39 \n",
            "\n",
            "Spearman Result :\n",
            " statistic = 0.66 \n",
            " pvalue = 2.5346056459149263e-45 \n",
            "\n",
            "Percentage of test words not known to the model :\n",
            " 0.0\n"
          ]
        }
      ],
      "source": [
        "# Calcul du score du modèle word2vec sur les données ``WordSimilarity-353``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "\n",
        "print('Pearson  Result :\\n statistic =', round(similarities[0][0],2), '\\n pvalue =', similarities[0][1], '\\n\\n' +\n",
        "      'Spearman Result :\\n statistic =', round(similarities[1][0],2), '\\n pvalue =', similarities[1][1], '\\n\\n' +\n",
        "      'Percentage of test words not known to the model :\\n', similarities[2])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JQtWzqxTyZ5r"
      },
      "source": [
        "---\n",
        "\n",
        "**Comment le score est-il calculé ? Que mesure-t-il ?**\n",
        "\n",
        "Les scores fournis lorsqu'on évalue notre modèle sur les données de ce fichier sont les scores de Pearson et Spearman ; deux mesures nous fournissant un coefficient de corrélation entre les scores de similarité humaine et les scores de similarité prédits par le modèle. Ces deux coefficient sont compris entre -1 et 1, où -1 représente une corrélation négative parfaite, 0 représente aucune corrélation, et 1 représente une corrélation positive parfaite.\n",
        "\n",
        "Le fichier `wordsim353.tsv` contient des paires de mots et leur score de similarité humaine - c'est-à-dire humainement attribué. Ainsi, ces deux scores nous permettent ici de mesurer la performance du modèle sur les données de `wordsim353.tsv`, selon deux types de corrélation.\n",
        "\n",
        "Définissons maintenant ces deux coefficients : \n",
        "\n",
        "* <u>Pearson</u> : Évalue la relation linéaire entre les similarités observées par le modèle et les véridiques, c'est-à-dire le degré d'alignement du nuage de points formé par les résultats attendus et véridiques ;\n",
        "\n",
        "* <u>Spearman</u> : Évalue à quel point la relation entre deux variables peut être décrite par une fonction monotone. Elle est étudiée lorsque deux variables statistiques semblent corrélées sans que la relation entre les deux variables soit de type affine. Elle consiste à trouver un coefficient de corrélation, non pas entre les valeurs prises par les deux variables mais entre les rangs de ces valeurs.\n",
        "\n",
        "La p-value - quant à elle - mesure la probabilité que la corrélation observée soit due au hasard ou non. D'après nos recherches, une valeur faible - généralement définie comme inférieure à 0.05 - indique qu'il est peu probable que la statistique de corrélation observée ait été obtenue par hasard et que la corrélation est donc statistiquement significative. En revanche, une p-value élevée indique que la statistique de corrélation observée pourrait être due au hasard, et que la corrélation n'est donc pas statistiquement significative. \n",
        "\n",
        "Dans les deux cas ici, on observe une valeur très proche de zéro pour la p-value ; on en conclut ainsi que les coefficients de corrélation observés sont significatifs et donc recevables.\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mV43xK83zK5i"
      },
      "outputs": [],
      "source": [
        "# Calcul du score du modèle word2vec sur les données ``questions-words.txt``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-nTsdcV3EoW",
        "outputId": "f15a0c43-3a01-46e9-ee02-f645f8e6c9d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.74"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "round('Analogy score :', analogy_scores[0], 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "znNb0Cuh0GFR"
      },
      "source": [
        "---\n",
        "\n",
        "**Comment le score est-il calculé ? Que mesure-t-il ?**\n",
        "\n",
        "Ce score mesure la performance du modèle sur le set d'évaluation - `questions-words.txt` ici, il s'agit de l'équivalent de l'accuracy sur une tâche d'analogie de mots. L'évaluation d'un modèle Word2Vec sur une tâche d'analogie de mots permet de mesurer sa capacité à comprendre les relations sémantiques entre les mots, ce qui est une indication de sa qualité en tant que modèle de représentation de mots.\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pt6j3FdO0yN_"
      },
      "source": [
        "# 2. Entraîner deux nouveaux modèles word2vec à partir de nouveaux corpus\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SVMPOmH0Gfz",
        "outputId": "06b05850-9a26-4fbe-e1fe-e2f7aefc910d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
          ]
        }
      ],
      "source": [
        "# Récupération du corpus contenant les 10^8 premiers caractères de Wikipédia (en anglais)\n",
        "import gensim.downloader as api\n",
        "\n",
        "corpus = api.load('text8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J3-IIBm1Nv2",
        "outputId": "2b8c0888-f2ce-4ab7-ebd8-38f375b06c83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'num_records': 1701,\n",
              " 'record_format': 'list of str (tokens)',\n",
              " 'file_size': 33182058,\n",
              " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py',\n",
              " 'license': 'not found',\n",
              " 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.',\n",
              " 'checksum': '68799af40b6bda07dfa47a32612e5364',\n",
              " 'file_name': 'text8.gz',\n",
              " 'read_more': ['http://mattmahoney.net/dc/textdata.html'],\n",
              " 'parts': 1}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "api.info('text8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBPqpepxFDsl",
        "outputId": "441edecb-23d4-4967-f787-2ec8e6394c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences in the corpus : 1701\n"
          ]
        }
      ],
      "source": [
        "# Nombre de phrases du corpus \n",
        "print('Number of sentences in the corpus :', api.info('text8')['num_records'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMG3M4Jz1RYv",
        "outputId": "f8198d99-065f-4190-8a8c-c8307cec42a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens in the corpus : 17005207\n"
          ]
        }
      ],
      "source": [
        "# Nombre de mots (token) du corpus\n",
        "\n",
        "print('Number of tokens in the corpus :', sum(len(token) for token in corpus))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QjZJ-_YLC5Dy"
      },
      "outputs": [],
      "source": [
        "# Entraînement d'un nouveau modèle word2vec sur ce nouveau corpus\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(corpus, vector_size=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8e3mIHAH48C",
        "outputId": "fbb30329-a7b9-4e8f-eee7-0081e41987ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension choosed for the new model's embedding : 300\n"
          ]
        }
      ],
      "source": [
        "w2v_vectors = model.wv\n",
        "\n",
        "print('Dimension choosed for the new model\\'s embedding :', w2v_vectors.vector_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W_91rCvTF9uC"
      },
      "source": [
        "---\n",
        "\n",
        "**Remarque :**\n",
        "\n",
        "*Le choix de la dimension choisie pour l'embedding de ce modèle a été fait de sorte à choisir la même dimension que ceux du modèle word2vec pré-entraîné sur les données Google News, ceci afin de permettre une comparaison sur une même base vectorielle.*\n",
        "\n",
        "**• Combien de temps prend l’entraînement sur le corpus total ?**\n",
        "\n",
        "1m 27s.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_oXT_CwdaYW",
        "outputId": "854bac19-c96f-46e0-d31c-c43ef4f99ab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model size is 2.08 Mo.\n"
          ]
        }
      ],
      "source": [
        "# Taille (en Mo) du modèle word2vec résultant \n",
        "import sys\n",
        "\n",
        "model.save('word2vec_text8.model')\n",
        "\n",
        "print('The model size is 2.08 Mo.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V02pwz2F0x-",
        "outputId": "d0692e50-295f-4af5-c9bd-5c794cedeb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pearson  Result :\n",
            " statistic = 0.61 \n",
            " pvalue = 6.883556714314934e-37 \n",
            "\n",
            "Spearman Result :\n",
            " statistic = 0.63 \n",
            " pvalue = 1.7145521521580297e-39 \n",
            "\n",
            "Ratio of pairs with unknown words :\n",
            " 0.56657223796034\n"
          ]
        }
      ],
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point i\n",
        "\n",
        "# Calcul du score du modèle sur les données ``WordSimilarity-353``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "\n",
        "print('Pearson  Result :\\n statistic =', round(similarities[0][0],2), '\\n pvalue =', similarities[0][1], '\\n\\n' +\n",
        "      'Spearman Result :\\n statistic =', round(similarities[1][0],2), '\\n pvalue =', similarities[1][1], '\\n\\n' +\n",
        "      'Ratio of pairs with unknown words :\\n', similarities[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKbpZ_gOGiTd",
        "outputId": "5ebfc320-620d-4562-8ff1-87f0c7c87d16"
      },
      "outputs": [],
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point j\n",
        "\n",
        "# Calcul du score du modèle word2vec sur les données ``questions-words.txt``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analogy score : 0.25775509059292084\n"
          ]
        }
      ],
      "source": [
        "print('Analogy score :', analogy_scores[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lHFYP5wFGm9D"
      },
      "source": [
        "---\n",
        "\n",
        "**Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle serait la raison de la différence ?**\n",
        "\n",
        "Tableau répicatulatif des scores :\n",
        "\n",
        "|                 | Pearson | Spearman | Analogy |\n",
        "| --------------- | ------- | -------- | ------- |\n",
        "| **text8**       | 0.61    | 0.63     | 0.25    |\n",
        "| **Google News** | 0.62    | 0.66     | 0.74    |\n",
        "\n",
        "\n",
        "\n",
        "ICI !!\n",
        "\n",
        "* Modèle entraîné sur Google News : Ces deux valeurs sont ici très proches (`Pearson : 62%`, `Spearman : 66%`) l'une de l'autre. On peut donc en conclure que les résultats du modèles sont plutôt corrélés avec les résultats attendus ; ces scores étant plus élevés que 50%. La corrélation n'est cependant pas très élevée, aux alentours de 60% ; ce qui nous fait penser que l'accuracy sera bonne mais pas notablement non plus.\n",
        "\n",
        "* \n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "kVP_j5fxHHij"
      },
      "outputs": [],
      "source": [
        "# Téléchargement du corpus quatre fois plus grand constitué de la concaténation du corpus text8\n",
        "# et des dépêches économiques de Reuters (413 Mo)\n",
        "from gensim.models.word2vec import Text8Corpus\n",
        "wiki_aug_model = Word2Vec(Text8Corpus('wikipedia_augmented.dat'), vector_size=300)\n",
        "wiki_aug_model.save(\"wikipedia_augmented.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "w2v_vectors = wiki_aug_model.wv\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La dimension choisie pour l'embedding de ce modèle reste identiques à celle des modèles précédents, c-à-d 300."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens in the corpus : 70102071\n"
          ]
        }
      ],
      "source": [
        "# Nombre de mots (token) du corpus\n",
        "corpus = Text8Corpus('wikipedia_augmented.dat')\n",
        "print('Number of tokens in the corpus :', sum(len(token) for token in corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Difference between text8 and widipedia augmented token is :  53096864\n"
          ]
        }
      ],
      "source": [
        "# La différence au niveau des tokens des différents corpus \n",
        "text8_token = 17005207 \n",
        "wikipedia_augmented_token=70102071\n",
        "diff = wikipedia_augmented_token - text8_token\n",
        "print(\"Difference between text8 and widipedia augmented token is : \",diff)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A8U8ebmmHYq5"
      },
      "source": [
        "---\n",
        "\n",
        "**• Combien de temps prend l’entraînement ?**\n",
        "\n",
        "Environ 6min 50s\n",
        "\n",
        "**• Quelle est la taille (en Mo) du modèle word2vec résultant ?**\n",
        "\n",
        "3.71Mo\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "jqRbEV_CHiFc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pearson  Result :\n",
            " statistic = 0.5 \n",
            " pvalue = 6.3654283708341675e-24 \n",
            "\n",
            "Spearman Result :\n",
            " statistic = 0.51 \n",
            " pvalue = 2.7513109548527965e-25 \n",
            "\n",
            "Ratio of pairs with unknown words :\n",
            " 0.0\n"
          ]
        }
      ],
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point i\n",
        "\n",
        "# Calcul du score du modèle sur les données ``WordSimilarity-353``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "\n",
        "print('Pearson  Result :\\n statistic =', round(similarities[0][0],2), '\\n pvalue =', similarities[0][1], '\\n\\n' +\n",
        "      'Spearman Result :\\n statistic =', round(similarities[1][0],2), '\\n pvalue =', similarities[1][1], '\\n\\n' +\n",
        "      'Ratio of pairs with unknown words :\\n', similarities[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "I07rjAW3Hnc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.35773330432891015"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point j\n",
        "\n",
        "# Calcul du score du modèle word2vec sur les données ``questions-words.txt``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
        "\n",
        "analogy_scores[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MKWOYQKSHqsX"
      },
      "source": [
        "---\n",
        "\n",
        "**Est-il meilleur que le précédent ? Pour quelle raison ?**\n",
        "\n",
        "wesh\n",
        "\n",
        "---\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tableau répicatulatif des scores :\n",
        "\n",
        "|                         | Pearson | Spearman | Analogy |\n",
        "| ----------------------- | ------- | -------- | ------- |\n",
        "| **text8**               | 0.61    | 0.63     | 0.25    |\n",
        "| **Google News**         | 0.62    | 0.66     | 0.74    |\n",
        "| **Wikipedia Augmented** | 0.5     | 0.51     | 0.35    |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GUORY2-jHv1_"
      },
      "source": [
        "Fin du labo."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "CoursTAL",
      "language": "python",
      "name": "courstal"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
