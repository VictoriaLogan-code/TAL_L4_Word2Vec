{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tester et évaluer un modèle entraîné sur Google News\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "y1hsBExwZq2a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS_r82oSZYxm",
        "outputId": "5c573c3b-998e-4751-96fc-fc7f50d87c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_vectors = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "EqV5KnWBZaeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1888b2-6947-4352-fd38-ed7f2ceeff4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Place mémoire occupée par le processus du notebook une fois les vecteurs de mots chargés "
      ],
      "metadata": {
        "id": "s_LTslKHclup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension de l'espace vectoriel dans lequel les mots sont représentés\n",
        "print('Dimension :', w2v_vectors.vector_size)"
      ],
      "metadata": {
        "id": "6Jbb7C48cv89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3aeb5b-6f60-4ef4-ab7b-16cb76ee62f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension : 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taille du voc (nombre de mots différents) et 5 mots du voc, 2 mots hors voc\n",
        "print('Taille du voc   :', len(w2v_vectors))\n",
        "print('5 mots du voc   :', list(w2v_vectors.key_to_index.keys())[100:105])\n",
        "print('5 mots hors voc : [\\'of\\', \\'to\\']')\n"
      ],
      "metadata": {
        "id": "5vrKpyl5dAIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449ec938-5a27-4baf-f5f3-0623095cd137"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du voc   : 3000000\n",
            "5 mots du voc   : ['company', 'any', 'team', 'against', 'off']\n",
            "5 mots hors voc : ['of', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#w2v_vectors['of']\n",
        "#w2v_vectors['to']"
      ],
      "metadata": {
        "id": "77v7JXtrgi_w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distance entre les mots `rabbit` et `carrot`\n",
        "round(w2v_vectors.similarity(\"rabbit\", \"carrot\"), 2)"
      ],
      "metadata": {
        "id": "G-abbD9deSmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a7da57-6aac-433b-c885-26dbd168c54d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Comment mesure-t-on ls distances entre deux mots dans cet espace ?**\n",
        "\n",
        "\n",
        "Dans cet espace, on mesure les distances entre deux mot en utilisant la similarité cosinus, c'est-à-dire qu'on va observer l'angle formé entre les vecteurs représentant les mots. La similarité cosinus calcule le cosinus de cet angle ; ainsi, voici comment interpréter les résultats de cette métrique :     \n",
        "*  1 : les deux vecteurs sont identiques ;\n",
        "*  0 : les deux mots n'ont pas de rapport ;\n",
        "* -1 : les deux mots sont opposés.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TJcZ9MP5ifG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distance entre entre 5 paires de mots\n",
        "words = ['wine', 'grapes', 'happy', 'sad', 'claws']\n",
        "\n",
        "for i in range(5):\n",
        "  w1 = words[i]\n",
        "  w2 = words[(i+1)%4]\n",
        "  print(w1, 'et', w2, ':', round(w2v_vectors.similarity(w1, w2), 2))"
      ],
      "metadata": {
        "id": "w4tbTAskhju4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Les distances obtenues correspondent-t-elles à vos intuitions sur la proximité des sens des mots ?**\n",
        "\n",
        "Ces distances ne correspondent pas toutes à nos intuitions. Effectivement, bien que wine et grapes aient un score de similarity élevé comme on s'y attendait, on observe également une similarité positive plutôt élevée entre ``sad`` et ``happy``, alors qu'on aurait tendance à s'attendre à une valeur négative proche de -1 - de par leur sens opposé. \n",
        "\n",
        "\n",
        " En réfléchissant un peu cependant, ça peut faire sens qu'ils soient proches étant donné que les deux expriment des émotions ; en ce sens là, ils sont proches. Aussi, word2vec est entraîné de sorte à valoriser la similarité des mots se retrouvant souvent ensemble dans les textes. Ce dernier argument nous indique encore une fois pourquoi notre intuition n'était pas correcte, ici.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "qyFIPt_3lG0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pouvez-vous trouver des mots de sens opposés mais qui sont proches dans l’espace vectoriel ? Comment expliquez vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?**\n",
        "\n",
        "Comme vu ci-dessus, les mots ``happy`` et ``sad`` sont considérés comme plutôt proches par le modèle word2vec pré-entraîné sur le corpus Google News, avec un score de 0.54. D'après le sens opposé des deux mots, on aurait tendance à supposer que leur score soit dans les négatifs, proche de -1. \n",
        "\n",
        "D'après nous, ceci s'explique premièrement par le fait que le modèle word2vec considère deux mots comme proches s'ils ont tendance à se retrouver dans les mêmes documents. Étant donné que le modèle qu'on utilise ici a été pré-entraîné sur le corpus Google News - qui comporte des articles en tous genres - le fait de trouver deux mots évoquant des émotions à sens opposé dans un même document n'est pas très surprenant ; ce qui aurait été le cas s'il s'agissait de textes de personnes évoquant leur vécu par rapport à une situation, par exemple. En somme, ces mots sont considérés comme proches certainement car ils expriment les deux des émotions, et sont donc similaires en cet aspect.\n",
        "\n",
        "L'aspect de qualité ou de défaut est difficile à juger ici, étant donné que cette catégorisation dépendra de l'utilisation que l'on souhaite faire du modèle. Si l'on cherche à classifier des mots comme étant proches lorsqu'ils ont une dfinition, un sens profond, similaire et inversément, alors ce modèle n'est pas adapté."
      ],
      "metadata": {
        "id": "iBfFOBxRmbxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcul du score du modèle word2vec sur les données ``WordSimilarity-353``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "\n",
        "print('Pearson  Result :\\n statistic =', round(similarities[0][0],2), '\\n pvalue =', similarities[0][1], '\\n\\n' +\n",
        "      'Spearman Result :\\n statistic =', round(similarities[1][0],2), '\\n pvalue =', similarities[1][1], '\\n\\n' +\n",
        "      'Percentage of test words not known to the model :\\n', similarities[2])"
      ],
      "metadata": {
        "id": "gBNGfz1_q99X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3179b1f3-da6c-4301-9fc3-e40721d037d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson  Result :\n",
            " statistic = 0.62 \n",
            " pvalue = 1.796323396013409e-39 \n",
            "\n",
            "Spearman Result :\n",
            " statistic = 0.66 \n",
            " pvalue = 2.5346056459149263e-45 \n",
            "\n",
            "Percentage of test words not known to the model :\n",
            " 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Comment le score est-il calculé ? Que mesure-t-il ?**\n",
        "\n",
        "Les scores fournis lorsqu'on évalue notre modèle sur les données de ce fichier sont les scores de Pearson et Spearman ; deux mesures nous fournissant un coefficient de corrélation entre les scores de similarité humaine et les scores de similarité prédits par le modèle. Ces deux coefficient sont compris entre -1 et 1, où -1 représente une corrélation négative parfaite, 0 représente aucune corrélation, et 1 représente une corrélation positive parfaite.\n",
        "\n",
        "Le fichier `wordsim353.tsv` contient des paires de mots et leur score de similarité humaine - c'est-à-dire humainement attribué. Ainsi, ces deux scores nous permettent ici de mesurer la performance du modèle sur les données de `wordsim353.tsv`, selon deux types de corrélation.\n",
        "\n",
        "Définissons maintenant ces deux coefficients : \n",
        "\n",
        "* <u>Pearson</u> : Évalue la relation linéaire entre les similarités observées par le modèle et les véridiques, c'est-à-dire le degré d'alignement du nuage de points formé par les résultats attendus et véridiques ;\n",
        "\n",
        "* <u>Spearman</u> : Évalue à quel point la relation entre deux variables peut être décrite par une fonction monotone. Elle est étudiée lorsque deux variables statistiques semblent corrélées sans que la relation entre les deux variables soit de type affine. Elle consiste à trouver un coefficient de corrélation, non pas entre les valeurs prises par les deux variables mais entre les rangs de ces valeurs.\n",
        "\n",
        "La p-value - quant à elle - mesure la probabilité que la corrélation observée soit due au hasard ou non. D'après nos recherches, une valeur faible - généralement définie comme inférieure à 0.05 - indique qu'il est peu probable que la statistique de corrélation observée ait été obtenue par hasard et que la corrélation est donc statistiquement significative. En revanche, une p-value élevée indique que la statistique de corrélation observée pourrait être due au hasard, et que la corrélation n'est donc pas statistiquement significative. \n",
        "\n",
        "Dans les deux cas ici, on observe une valeur très proche de zéro pour la p-value ; on en conclut ainsi que les coefficients de corrélation oservés sont significatifs et donc recevables.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JQtWzqxTyZ5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcul du score du modèle word2vec sur les données ``questions-words.txt``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n"
      ],
      "metadata": {
        "id": "mV43xK83zK5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round('Analogy score :', analogy_scores[0], 2)"
      ],
      "metadata": {
        "id": "w-nTsdcV3EoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15a0c43-3a01-46e9-ee02-f645f8e6c9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.74"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Comment le score est-il calculé ? Que mesure-t-il ?**\n",
        "\n",
        "Ce score mesure la performance du modèle sur le set d'évaluation - `questions-words.txt` ici, il s'agit de l'équivalent de l'accuracy sur une tâche d'analogie de mots. L'évaluation d'un modèle Word2Vec sur une tâche d'analogie de mots permet de mesurer sa capacité à comprendre les relations sémantiques entre les mots, ce qui est une indication de sa qualité en tant que modèle de représentation de mots.\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "znNb0Cuh0GFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Entraîner deux nouveaux modèles word2vec à partir de nouveaux corpus\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pt6j3FdO0yN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Récupération du corpus contenant les 10^8 premiers caractères de Wikipédia (en anglais)\n",
        "import gensim.downloader as api\n",
        "\n",
        "corpus = api.load('text8')"
      ],
      "metadata": {
        "id": "1SVMPOmH0Gfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b05850-9a26-4fbe-e1fe-e2f7aefc910d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api.info('text8')"
      ],
      "metadata": {
        "id": "6J3-IIBm1Nv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8c0888-f2ce-4ab7-ebd8-38f375b06c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_records': 1701,\n",
              " 'record_format': 'list of str (tokens)',\n",
              " 'file_size': 33182058,\n",
              " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py',\n",
              " 'license': 'not found',\n",
              " 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.',\n",
              " 'checksum': '68799af40b6bda07dfa47a32612e5364',\n",
              " 'file_name': 'text8.gz',\n",
              " 'read_more': ['http://mattmahoney.net/dc/textdata.html'],\n",
              " 'parts': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre de phrases du corpus \n",
        "print('Nombre de phrases du corpus :', api.info('text8')['num_records'])"
      ],
      "metadata": {
        "id": "aBPqpepxFDsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441edecb-23d4-4967-f787-2ec8e6394c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de phrases du corpus : 1701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre de mots (token) du corpus\n",
        "nb_token = 0\n",
        "\n",
        "for sentence in corpus:\n",
        "  nb_token += len(sentence)\n",
        "\n",
        "print('Nombre de mots (token) du corpus :', nb_token)"
      ],
      "metadata": {
        "id": "fMG3M4Jz1RYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8198d99-065f-4190-8a8c-c8307cec42a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de mots (token) du corpus : 17005207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement d'un nouveau modèle word2vec sur ce nouveau corpus\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(corpus, vector_size=300)"
      ],
      "metadata": {
        "id": "QjZJ-_YLC5Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_vectors = model.wv\n",
        "\n",
        "print('Dimension choisie pour l\\'embedding de ce nouveau modèle :', w2v_vectors.vector_size)"
      ],
      "metadata": {
        "id": "w8e3mIHAH48C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb30329-a7b9-4e8f-eee7-0081e41987ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension choisie pour l'embedding de ce nouveau modèle : 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Remarque :**\n",
        "\n",
        "*Le choix de la dimension choisie pour l'embedding de ce modèle a été fait de sorte à choisir la même dimension que ceux du modèle word2vec pré-entraîné sur les données Google News, ceci afin de permettre une comparaison sur une même base vectorielle.*\n",
        "\n",
        "**• Combien de temps prend l’entraînement sur le corpus total ?**\n",
        "\n",
        "4 minutes.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "W_91rCvTF9uC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Taille (en Mo) du modèle word2vec résultant \n",
        "import sys\n",
        "\n",
        "model.save('word2vec_text8.model')\n",
        "\n",
        "print('Le modèle resultant a une taille de 2.2 Mo.')"
      ],
      "metadata": {
        "id": "K_oXT_CwdaYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854bac19-c96f-46e0-d31c-c43ef4f99ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le modèle resultant a une taille de 2.2 Mo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point i\n",
        "\n",
        "# Calcul du score du modèle sur les données ``WordSimilarity-353``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "\n",
        "print('Pearson  Result :\\n statistic =', round(similarities[0][0],2), '\\n pvalue =', similarities[0][1], '\\n\\n' +\n",
        "      'Spearman Result :\\n statistic =', round(similarities[1][0],2), '\\n pvalue =', similarities[1][1], '\\n\\n' +\n",
        "      'Ratio of pairs with unknown words :\\n', similarities[2])"
      ],
      "metadata": {
        "id": "_V02pwz2F0x-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0692e50-295f-4af5-c9bd-5c794cedeb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson  Result :\n",
            " statistic = 0.62 \n",
            " pvalue = 3.330486314781905e-38 \n",
            "\n",
            "Spearman Result :\n",
            " statistic = 0.64 \n",
            " pvalue = 2.3928242389526e-41 \n",
            "\n",
            "Ratio of pairs with unknown words :\n",
            " 0.56657223796034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point j\n",
        "\n",
        "# Calcul du score du modèle word2vec sur les données ``questions-words.txt``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
        "\n",
        "round('Analogy score :', round(analogy_scores[0],2))"
      ],
      "metadata": {
        "id": "dKbpZ_gOGiTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebfc320-620d-4562-8ff1-87f0c7c87d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle serait la raison de la différence ?**\n",
        "\n",
        "Tableau répicatulatif des scores :\n",
        "\n",
        "|                 | Pearson | Spearman | Analogy |\n",
        "| --------------- | ------- | -------- | ------- |\n",
        "| **text8**       | 0.62    | 0.64     | 0.25    |\n",
        "| **Google News** | 0.62    | 0.66     | 0.74    |\n",
        "\n",
        "\n",
        "\n",
        "ICI !!\n",
        "\n",
        "* Modèle entraîné sur Google News : Ces deux valeurs sont ici très proches (`Pearson : 62%`, `Spearman : 66%`) l'une de l'autre. On peut donc en conclure que les résultats du modèles sont plutôt corrélés avec les résultats attendus ; ces scores étant plus élevés que 50%. La corrélation n'est cependant pas très élevée, aux alentours de 60% ; ce qui nous fait penser que l'accuracy sera bonne mais pas notablement non plus.\n",
        "\n",
        "* \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "lHFYP5wFGm9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Téléchargement du corpus quatre fois plus grand constitué de la concaténation du corpus text8\n",
        "# et des dépêches économiques de Reuters (413 Mo)"
      ],
      "metadata": {
        "id": "kVP_j5fxHHij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement d'un nouveau modèle word2vec sur ce corpus, en précisant la dimension du plongement (embedding)"
      ],
      "metadata": {
        "id": "iRNFizcDHPCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**• Utilisez la classe Text8Corpus() pour charger le corpus et faire la tokenization et la segmentation en phrases.**\n",
        "\n",
        "wesh\n",
        "\n",
        "**• Combien de temps prend l’entraînement ?**\n",
        "\n",
        "wesh\n",
        "\n",
        "**• Quelle est la taille (en Mo) du modèle word2vec résultant ?**\n",
        "\n",
        "wesh\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "A8U8ebmmHYq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point i\n",
        "\n",
        "# Calcul du score du modèle sur les données ``WordSimilarity-353``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "\n",
        "print('Pearson  Result :\\n statistic =', round(similarities[0][0],2), '\\n pvalue =', similarities[0][1], '\\n\\n' +\n",
        "      'Spearman Result :\\n statistic =', round(similarities[1][0],2), '\\n pvalue =', similarities[1][1], '\\n\\n' +\n",
        "      'Ratio of pairs with unknown words :\\n', similarities[2])"
      ],
      "metadata": {
        "id": "jqRbEV_CHiFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point j\n",
        "\n",
        "# Calcul du score du modèle word2vec sur les données ``questions-words.txt``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
        "\n",
        "analogy_scores[0]"
      ],
      "metadata": {
        "id": "I07rjAW3Hnc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Est-il meilleur que le précédent ? Pour quelle raison ?**\n",
        "\n",
        "wesh\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "MKWOYQKSHqsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fin du labo."
      ],
      "metadata": {
        "id": "GUORY2-jHv1_"
      }
    }
  ]
}