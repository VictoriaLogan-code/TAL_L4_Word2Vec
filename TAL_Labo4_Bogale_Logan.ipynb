{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tester et évaluer un modèle entraîné sur Google News\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "y1hsBExwZq2a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS_r82oSZYxm",
        "outputId": "abe6a5fb-4ec2-4c12-bf01-599cc4fd9250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_vectors = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "EqV5KnWBZaeX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Place mémoire occupée par le processus du notebook une fois les vecteurs de mots chargés \n",
        "import psutil\n",
        "import os\n",
        "memory_usage_bytes = psutil.Process(os.getpid()).memory_info().rss\n",
        "memory_usage_mb = round(memory_usage_bytes / (1024 * 1024), 2) # 19.6 MB at this point\n",
        "print('The amount of memory occupied by the notebook process once the word vectors are loaded is : 19.6 MB')"
      ],
      "metadata": {
        "id": "s_LTslKHclup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730a2b60-a6a9-41dd-db23-f9dd97af57b1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The amount of memory occupied by the notebook process once the word vectors are loaded is : 19.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension de l'espace vectoriel dans lequel les mots sont représentés\n",
        "print('Dimension :', w2v_vectors.vector_size)"
      ],
      "metadata": {
        "id": "6Jbb7C48cv89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b635ba4-a578-40a5-ab7c-13aa32fe58ad"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension : 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taille du voc (nombre de mots différents) et 5 mots du voc, 2 mots hors voc\n",
        "print('Taille du voc   :', len(w2v_vectors))\n",
        "print('5 mots du voc   :', list(w2v_vectors.key_to_index.keys())[100:105])\n",
        "print('5 mots hors voc : [\\'of\\', \\'to\\']')\n"
      ],
      "metadata": {
        "id": "5vrKpyl5dAIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea8fa1c-7b2f-41ad-ab5f-0b3f20dea14f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du voc   : 3000000\n",
            "5 mots du voc   : ['company', 'any', 'team', 'against', 'off']\n",
            "5 mots hors voc : ['of', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#w2v_vectors['Vexillology']\n",
        "#w2v_vectors['Clinomania']"
      ],
      "metadata": {
        "id": "77v7JXtrgi_w"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distance entre les mots `rabbit` et `carrot`\n",
        "round(w2v_vectors.similarity(\"rabbit\", \"carrot\"), 2)"
      ],
      "metadata": {
        "id": "G-abbD9deSmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7006df37-65c1-4378-b5ce-b90548029d0b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Comment mesure-t-on ls distances entre deux mots dans cet espace ?**\n",
        "\n",
        "\n",
        "Dans cet espace, on mesure les distances entre deux mot en utilisant la similarité cosinus, c'est-à-dire qu'on va observer l'angle formé entre les vecteurs représentant les mots. La similarité cosinus calcule le cosinus de cet angle ; ainsi, voici comment interpréter les résultats de cette métrique :     \n",
        "*  1 : les deux vecteurs sont identiques ;\n",
        "*  0 : les deux mots n'ont pas de rapport ;\n",
        "* -1 : les deux mots sont opposés.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TJcZ9MP5ifG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distance entre entre 5 paires de mots\n",
        "words = ['wine', 'grapes', 'happy', 'sad', 'claws']\n",
        "\n",
        "for i in range(5):\n",
        "  w1 = words[i]\n",
        "  w2 = words[(i+1)%4]\n",
        "  print(w1, 'et', w2, ':', round(w2v_vectors.similarity(w1, w2), 2))"
      ],
      "metadata": {
        "id": "w4tbTAskhju4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f89e8ef-f487-44a9-a455-746163a3454b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wine et grapes : 0.65\n",
            "grapes et happy : 0.07\n",
            "happy et sad : 0.54\n",
            "sad et wine : 0.02\n",
            "claws et grapes : 0.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Les distances obtenues correspondent-t-elles à vos intuitions sur la proximité des sens des mots ?**\n",
        "\n",
        "Ces distances ne correspondent pas toutes à nos intuitions. Effectivement, bien que wine et grapes aient un score de similarity élevé comme on s'y attendait, on observe également une similarité positive plutôt élevée entre ``sad`` et ``happy``, alors qu'on aurait tendance à s'attendre à une valeur négative proche de -1 - de par leur sens opposé. \n",
        "\n",
        "\n",
        " En réfléchissant un peu cependant, ça peut faire sens qu'ils soient proches étant donné que les deux expriment des émotions ; en ce sens là, ils sont proches. Aussi, word2vec est entraîné de sorte à valoriser la similarité des mots se retrouvant souvent ensemble dans les textes. Ce dernier argument nous indique encore une fois pourquoi notre intuition n'était pas correcte, ici.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "qyFIPt_3lG0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pouvez-vous trouver des mots de sens opposés mais qui sont proches dans l’espace vectoriel ? Comment expliquez vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?**\n",
        "\n",
        "Comme vu ci-dessus, les mots ``happy`` et ``sad`` sont considérés comme plutôt proches par le modèle word2vec pré-entraîné sur le corpus Google News, avec un score de 0.54. D'après le sens opposé des deux mots, on aurait tendance à supposer que leur score soit dans les négatifs, proche de -1. \n",
        "\n",
        "D'après nous, ceci s'explique premièrement par le fait que le modèle word2vec considère deux mots comme proches s'ils ont tendance à se retrouver dans les mêmes documents. Étant donné que le modèle qu'on utilise ici a été pré-entraîné sur le corpus Google News - qui comporte des articles en tous genres - le fait de trouver deux mots évoquant des émotions à sens opposé dans un même document n'est pas très surprenant ; ce qui aurait été le cas s'il s'agissait de textes de personnes évoquant leur vécu par rapport à une situation, par exemple. En somme, ces mots sont considérés comme proches certainement car ils expriment les deux des émotions, et sont donc similaires en cet aspect.\n",
        "\n",
        "L'aspect de qualité ou de défaut est difficile à juger ici, étant donné que cette catégorisation dépendra de l'utilisation que l'on souhaite faire du modèle. Si l'on cherche à classifier des mots comme étant proches lorsqu'ils ont une dfinition, un sens profond, similaire et inversément, alors ce modèle n'est pas adapté."
      ],
      "metadata": {
        "id": "iBfFOBxRmbxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcul du score du modèle word2vec sur les données ``WordSimilarity-353``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "\n",
        "print('Pearson  Result :\\n statistic =', round(similarities[0][0],2), '\\n pvalue =', similarities[0][1], '\\n\\n' +\n",
        "      'Spearman Result :\\n statistic =', round(similarities[1][0],2), '\\n pvalue =', similarities[1][1], '\\n\\n' +\n",
        "      'Percentage of test words not known to the model :\\n', similarities[2])"
      ],
      "metadata": {
        "id": "gBNGfz1_q99X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0ec315-6ad0-4968-b8da-6406146d13ad"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson  Result :\n",
            " statistic = 0.62 \n",
            " pvalue = 1.796323396013409e-39 \n",
            "\n",
            "Spearman Result :\n",
            " statistic = 0.66 \n",
            " pvalue = 2.5346056459149263e-45 \n",
            "\n",
            "Percentage of test words not known to the model :\n",
            " 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Comment le score est-il calculé ? Que mesure-t-il ?**\n",
        "\n",
        "Les scores fournis lorsqu'on évalue notre modèle sur les données de ce fichier sont les scores de Pearson et Spearman ; deux mesures nous fournissant un coefficient de corrélation entre les scores de similarité humaine et les scores de similarité prédits par le modèle. Ces deux coefficient sont compris entre -1 et 1, où -1 représente une corrélation négative parfaite, 0 représente aucune corrélation, et 1 représente une corrélation positive parfaite.\n",
        "\n",
        "Le fichier `wordsim353.tsv` contient des paires de mots et leur score de similarité humaine - c'est-à-dire humainement attribué. Ainsi, ces deux scores nous permettent ici de mesurer la performance du modèle sur les données de `wordsim353.tsv`, selon deux types de corrélation.\n",
        "\n",
        "Définissons maintenant ces deux coefficients : \n",
        "\n",
        "* <u>Pearson</u> : Évalue la relation linéaire entre les similarités observées par le modèle et les véridiques, c'est-à-dire le degré d'alignement du nuage de points formé par les résultats attendus et véridiques ;\n",
        "\n",
        "* <u>Spearman</u> : Évalue à quel point la relation entre deux variables peut être décrite par une fonction monotone. Elle est étudiée lorsque deux variables statistiques semblent corrélées sans que la relation entre les deux variables soit de type affine. Elle consiste à trouver un coefficient de corrélation, non pas entre les valeurs prises par les deux variables mais entre les rangs de ces valeurs.\n",
        "\n",
        "La p-value - quant à elle - mesure la probabilité que la corrélation observée soit due au hasard ou non. D'après nos recherches, une valeur faible - généralement définie comme inférieure à 0.05 - indique qu'il est peu probable que la statistique de corrélation observée ait été obtenue par hasard et que la corrélation est donc statistiquement significative. En revanche, une p-value élevée indique que la statistique de corrélation observée pourrait être due au hasard, et que la corrélation n'est donc pas statistiquement significative. \n",
        "\n",
        "Dans les deux cas ici, on observe une valeur très proche de zéro pour la p-value ; on en conclut ainsi que les coefficients de corrélation oservés sont significatifs et donc recevables.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JQtWzqxTyZ5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcul du score du modèle word2vec sur les données ``questions-words.txt``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n"
      ],
      "metadata": {
        "id": "mV43xK83zK5i"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Analogy score :', round(analogy_scores[0], 2))"
      ],
      "metadata": {
        "id": "w-nTsdcV3EoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f064db61-add6-4051-c0fa-b21e133d5ba6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy score : 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Comment le score est-il calculé ? Que mesure-t-il ?**\n",
        "\n",
        "Ce score mesure la performance du modèle sur le set d'évaluation - `questions-words.txt` ici, il s'agit de l'équivalent de l'accuracy sur une tâche d'analogie de mots. L'évaluation d'un modèle Word2Vec sur une tâche d'analogie de mots permet de mesurer sa capacité à comprendre les relations sémantiques entre les mots, ce qui est une indication de sa qualité en tant que modèle de représentation de mots.\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "znNb0Cuh0GFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Entraîner deux nouveaux modèles word2vec à partir de nouveaux corpus\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pt6j3FdO0yN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Récupération du corpus contenant les 10^8 premiers caractères de Wikipédia (en anglais)\n",
        "import gensim.downloader as api\n",
        "\n",
        "corpus = api.load('text8')"
      ],
      "metadata": {
        "id": "1SVMPOmH0Gfz"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api.info('text8')"
      ],
      "metadata": {
        "id": "6J3-IIBm1Nv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622927bd-c6fc-4b71-e677-d4a1a3b52d94"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_records': 1701,\n",
              " 'record_format': 'list of str (tokens)',\n",
              " 'file_size': 33182058,\n",
              " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py',\n",
              " 'license': 'not found',\n",
              " 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.',\n",
              " 'checksum': '68799af40b6bda07dfa47a32612e5364',\n",
              " 'file_name': 'text8.gz',\n",
              " 'read_more': ['http://mattmahoney.net/dc/textdata.html'],\n",
              " 'parts': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre de phrases du corpus \n",
        "print('Nombre de phrases du corpus :', api.info('text8')['num_records'])"
      ],
      "metadata": {
        "id": "aBPqpepxFDsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d33d90-2b96-4ad4-a960-d35388f6e356"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de phrases du corpus : 1701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre de mots (token) du corpus\n",
        "text8_nb_token = 0\n",
        "\n",
        "for sentence in corpus:\n",
        "  text8_nb_token += len(sentence)\n",
        "\n",
        "print('Nombre de mots (token) du corpus :', text8_nb_token)"
      ],
      "metadata": {
        "id": "fMG3M4Jz1RYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7973e1ff-9062-44b5-bd4c-81c739e63f4c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de mots (token) du corpus : 17005207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement d'un nouveau modèle word2vec sur ce nouveau corpus\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(corpus, vector_size=300)"
      ],
      "metadata": {
        "id": "QjZJ-_YLC5Dy"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_vectors = model.wv\n",
        "\n",
        "print('Dimension choisie pour l\\'embedding de ce nouveau modèle :', w2v_vectors.vector_size)"
      ],
      "metadata": {
        "id": "w8e3mIHAH48C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e2ed5c0-c95d-435f-8df4-b6f2f97f8c5d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension choisie pour l'embedding de ce nouveau modèle : 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Remarque :**\n",
        "\n",
        "*Le choix de la dimension choisie pour l'embedding de ce modèle a été fait de sorte à choisir la même dimension que ceux du modèle word2vec pré-entraîné sur les données Google News, ceci afin de permettre une comparaison sur une même base vectorielle.*\n",
        "\n",
        "**• Combien de temps prend l’entraînement sur le corpus total ?**\n",
        "\n",
        "4 minutes.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "W_91rCvTF9uC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Taille (en Mo) du modèle word2vec résultant \n",
        "import sys\n",
        "\n",
        "model.save('word2vec_text8.model')\n",
        "\n",
        "print('Le modèle resultant a une taille de 2.2 Mo.')"
      ],
      "metadata": {
        "id": "K_oXT_CwdaYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52591bb9-a09b-4893-9489-1d432d5d197e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le modèle resultant a une taille de 2.2 Mo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point i\n",
        "\n",
        "# Calcul du score du modèle sur les données ``WordSimilarity-353``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "\n",
        "print('Pearson  Result :\\n statistic =', round(similarities[0][0],2), '\\n pvalue =', similarities[0][1], '\\n\\n' +\n",
        "      'Spearman Result :\\n statistic =', round(similarities[1][0],2), '\\n pvalue =', similarities[1][1], '\\n\\n' +\n",
        "      'Ratio of pairs with unknown words :\\n', similarities[2])"
      ],
      "metadata": {
        "id": "_V02pwz2F0x-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479a049f-48a5-4ba9-ec38-b825a9e6c95d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson  Result :\n",
            " statistic = 0.61 \n",
            " pvalue = 7.27647717939324e-38 \n",
            "\n",
            "Spearman Result :\n",
            " statistic = 0.63 \n",
            " pvalue = 1.7354754042178484e-40 \n",
            "\n",
            "Ratio of pairs with unknown words :\n",
            " 0.56657223796034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point j\n",
        "\n",
        "# Calcul du score du modèle word2vec sur les données ``questions-words.txt``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
        "\n",
        "print('Analogy score :', round(analogy_scores[0],2))"
      ],
      "metadata": {
        "id": "dKbpZ_gOGiTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "216f2886-9ac0-47a3-ebae-7484ba62612a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy score : 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle serait la raison de la différence ?**\n",
        "\n",
        "Tableau répicatulatif des scores :\n",
        "\n",
        "|                 | Pearson | Spearman | Analogy |\n",
        "| --------------- | ------- | -------- | ------- |\n",
        "| **text8**       | 0.62    | 0.64     | 0.25    |\n",
        "| **Google News** | 0.62    | 0.66     | 0.74    |\n",
        "\n",
        "\n",
        "D'après le tableau récapitalif des scores ci-dessus, on voit que les coefficients de corrélations sont très proches d'un modèle à l'autre. On remarque cependant que le analogy score change grandement de l'un à l'autre ; étant médiocre du côté du modèle entraîné sur le corpus `text8`, il est plutôt bon du côté de celui entraîné sur `Google News`. Cela peut s'expliquer par le fait que le corpus `Google News` de notre modèle pré-entraîné contient 100 miliards de mots [(source)](https://github.com/RaRe-Technologies/gensim-data/blob/master/README.md), contre ... pour le corpus `text8` sur lequel nous avons créé notre nouveau modèle ; il n'est ainsi pas surprenant que le modèle entraîné sur le corpus `Google News` ait de meilleures performances. On voit également que le modèle entraîné sur text8 a un ratio d'environ 0.55 de mots inconnus, ce qui peut également expliquer le fait que le score soit bien plus bas.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "lHFYP5wFGm9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Téléchargement du corpus quatre fois plus grand constitué de la concaténation du corpus text8\n",
        "# et des dépêches économiques de Reuters (413 Mo)\n",
        "from gensim.models.word2vec import Text8Corpus\n",
        "\n",
        "corpus = Text8Corpus(\"wikipedia_augmented.dat\")\n",
        "\n",
        "text8_Reuters_nb_token = sum(len(s) for s in corpus)\n",
        "\n",
        "print('Le corpus text8 + Reuters contient :', text8_Reuters_nb_token, 'mots')\n"
      ],
      "metadata": {
        "id": "kVP_j5fxHHij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39cca549-7f48-46d0-d1f0-275e0c3623d2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le corpus text8 + Reuters contient : 70102071 mots\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement d'un nouveau modèle word2vec sur ce corpus, en précisant la dimension du plongement (embedding)\n",
        "model = Word2Vec(sentences=corpus, vector_size=300)\n",
        "\n",
        "model.save('word2vec_text8_Reuters.model')\n",
        "w2v_vectors = model.wv"
      ],
      "metadata": {
        "id": "iRNFizcDHPCZ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**• Combien de temps prend l’entraînement ?**\n",
        "\n",
        "8 minutes\n",
        "\n",
        "**• Quelle est la taille (en Mo) du modèle word2vec résultant ?**\n",
        "\n",
        "wesh\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "A8U8ebmmHYq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point i\n",
        "\n",
        "# Calcul du score du modèle sur les données ``WordSimilarity-353``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "\n",
        "print('Pearson  Result :\\n statistic =', round(similarities[0][0],2), '\\n pvalue =', similarities[0][1], '\\n\\n' +\n",
        "      'Spearman Result :\\n statistic =', round(similarities[1][0],2), '\\n pvalue =', similarities[1][1], '\\n\\n' +\n",
        "      'Ratio of pairs with unknown words :\\n', similarities[2])"
      ],
      "metadata": {
        "id": "jqRbEV_CHiFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205e2c72-6a0f-49eb-dda0-637db92b3b35"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson  Result :\n",
            " statistic = 0.52 \n",
            " pvalue = 2.548664873472273e-25 \n",
            "\n",
            "Spearman Result :\n",
            " statistic = 0.53 \n",
            " pvalue = 1.4991658646006056e-26 \n",
            "\n",
            "Ratio of pairs with unknown words :\n",
            " 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesure de la qualité de ce modèle comme dans la partie 1 point j\n",
        "\n",
        "# Calcul du score du modèle word2vec sur les données ``questions-words.txt``\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
        "\n",
        "print('Analogy score :', round(analogy_scores[0],2))"
      ],
      "metadata": {
        "id": "I07rjAW3Hnc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f9eec6-4d23-4a66-faf7-d43dc8fb05ea"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy score : 0.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# La différence au niveau des tokens des différents corpus \n",
        "\n",
        "print('Difference between text8 and widipedia augmented token is :', text8_Reuters_nb_token - text8_nb_token, '\\n' +\n",
        "      'Text8 corpus has', round(text8_nb_token*100/text8_Reuters_nb_token,2), '% of text8+Reuters\\' number of tokens')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPjihi0r-Jxt",
        "outputId": "191fb6d1-901b-42d9-a500-6642599ec14c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference between text8 and widipedia augmented token is : 53096864 \n",
            "Text8 corpus has 24.26 % of text8+Reuters' number of tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Est-il meilleur que le précédent ? Pour quelle raison ?**\n",
        "\n",
        "\n",
        "Tableau répicatulatif des scores :\n",
        "\n",
        "|                     | Pearson | Spearman | Analogy |\n",
        "| ------------------- | ------- | -------- | ------- |\n",
        "| **text8 + Reuters** | 0.52    | 0.53     | 0.36    |\n",
        "| **text8**           | 0.62    | 0.64     | 0.25    |\n",
        "\n",
        "On constate des coefficients de corrélation légèrement plus faibles pour ce corpus augmenté de Reuters. Concernant le score de performance analogy par contre, on observe une légèrement amélioration en augmentant le corpus. Ceci est dû au fait que le corpus contient beaucoup plus de token que le text8, ce qui permet un entraînement plus affiné et donc de meilleurs scores.\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "MKWOYQKSHqsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fin du labo."
      ],
      "metadata": {
        "id": "GUORY2-jHv1_"
      }
    }
  ]
}